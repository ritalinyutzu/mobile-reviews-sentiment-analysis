"""
æ‰‹æ©Ÿè©•è«–æƒ…æ„Ÿåˆ†æ - æ¢ç´¢æ€§æ•¸æ“šåˆ†æ (EDA)
Mobile Reviews Sentiment Analysis - Exploratory Data Analysis
"""

# %% å°å…¥å¥—ä»¶
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# è¨­å®š
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 12

# å‰µå»ºè¼¸å‡ºç›®éŒ„
Path('visualizations').mkdir(exist_ok=True)
Path('data/processed').mkdir(parents=True, exist_ok=True)

print("=" * 80)
print("æ‰‹æ©Ÿè©•è«–æƒ…æ„Ÿåˆ†æ - EDA")
print("=" * 80)

# %% è¼‰å…¥æ•¸æ“š
print("\nğŸ“‚ è¼‰å…¥æ•¸æ“š...")

# å˜—è©¦æ‰¾åˆ°æ•¸æ“šæ–‡ä»¶
data_path = Path('data/raw')
csv_files = list(data_path.glob('*.csv'))

if not csv_files:
    print("âŒ æœªæ‰¾åˆ°æ•¸æ“šæ–‡ä»¶")
    print("è«‹å…ˆé‹è¡Œ download_data.py ä¸‹è¼‰æ•¸æ“š")
    exit()

# è¼‰å…¥ä¸»è¦æ•¸æ“šæ–‡ä»¶
df = pd.read_csv(csv_files[0])

print(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸ")
print(f"æ•¸æ“šé›†: {csv_files[0].name}")
print(f"å½¢ç‹€: {df.shape[0]:,} è¡Œ Ã— {df.shape[1]} åˆ—")

# %% æ•¸æ“šåŸºæœ¬è³‡è¨Š
print("\n" + "=" * 80)
print("ğŸ“Š æ•¸æ“šåŸºæœ¬è³‡è¨Š")
print("=" * 80)

print("\næ¬„ä½åˆ—è¡¨:")
for i, col in enumerate(df.columns, 1):
    dtype = df[col].dtype
    null_count = df[col].isnull().sum()
    null_pct = (null_count / len(df)) * 100
    print(f"{i:2d}. {col:30s} | é¡å‹: {str(dtype):10s} | ç¼ºå¤±: {null_count:6,} ({null_pct:5.2f}%)")

print(f"\nç¸½è¨˜æ†¶é«”ä½¿ç”¨: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# %% æŸ¥çœ‹å‰å¹¾è¡Œ
print("\n" + "=" * 80)
print("ğŸ‘€ æ•¸æ“šé è¦½")
print("=" * 80)
print(df.head(10))

# %% æ•¸æ“šé¡å‹åˆ†ä½ˆ
print("\n" + "=" * 80)
print("ğŸ“‹ æ•¸æ“šé¡å‹åˆ†ä½ˆ")
print("=" * 80)

dtype_counts = df.dtypes.value_counts()
print(dtype_counts)

# %% æ•¸å€¼æ¬„ä½çµ±è¨ˆ
print("\n" + "=" * 80)
print("ğŸ“ˆ æ•¸å€¼æ¬„ä½çµ±è¨ˆ")
print("=" * 80)

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
if numeric_cols:
    print(df[numeric_cols].describe())
else:
    print("ç„¡æ•¸å€¼æ¬„ä½")

# %% ç¼ºå¤±å€¼åˆ†æ
print("\n" + "=" * 80)
print("ğŸ” ç¼ºå¤±å€¼åˆ†æ")
print("=" * 80)

missing = df.isnull().sum()
missing_pct = (missing / len(df)) * 100
missing_df = pd.DataFrame({
    'ç¼ºå¤±æ•¸é‡': missing,
    'ç¼ºå¤±ç™¾åˆ†æ¯”': missing_pct
}).sort_values('ç¼ºå¤±æ•¸é‡', ascending=False)

print(missing_df[missing_df['ç¼ºå¤±æ•¸é‡'] > 0])

if missing.sum() > 0:
    # è¦–è¦ºåŒ–ç¼ºå¤±å€¼
    plt.figure(figsize=(14, 6))
    missing_cols = missing_df[missing_df['ç¼ºå¤±æ•¸é‡'] > 0].head(15)
    
    plt.barh(range(len(missing_cols)), missing_cols['ç¼ºå¤±ç™¾åˆ†æ¯”'], color='coral', alpha=0.7)
    plt.yticks(range(len(missing_cols)), missing_cols.index)
    plt.xlabel('ç¼ºå¤±ç™¾åˆ†æ¯” (%)')
    plt.title('ç¼ºå¤±å€¼åˆ†æ - Top 15 æ¬„ä½', fontsize=16, fontweight='bold')
    plt.grid(True, alpha=0.3, axis='x')
    
    for i, v in enumerate(missing_cols['ç¼ºå¤±ç™¾åˆ†æ¯”']):
        plt.text(v + 0.5, i, f'{v:.1f}%', va='center')
    
    plt.tight_layout()
    plt.savefig('visualizations/01_missing_values.png', dpi=300, bbox_inches='tight')
    print("âœ… ç¼ºå¤±å€¼åœ–è¡¨å·²ä¿å­˜")
    plt.show()
else:
    print("âœ… ç„¡ç¼ºå¤±å€¼")

# %% è­˜åˆ¥æ–‡æœ¬æ¬„ä½å’Œæƒ…æ„Ÿæ¬„ä½
print("\n" + "=" * 80)
print("ğŸ”¤ è­˜åˆ¥é—œéµæ¬„ä½")
print("=" * 80)

# å°‹æ‰¾å¯èƒ½çš„è©•è«–æ–‡æœ¬æ¬„ä½
text_cols = []
for col in df.columns:
    if df[col].dtype == 'object':
        avg_length = df[col].astype(str).str.len().mean()
        if avg_length > 50:  # å‡è¨­è©•è«–æ–‡æœ¬é•·åº¦ > 50
            text_cols.append(col)
            print(f"æ–‡æœ¬æ¬„ä½: {col} (å¹³å‡é•·åº¦: {avg_length:.0f})")

# å°‹æ‰¾å¯èƒ½çš„æƒ…æ„Ÿ/è©•åˆ†æ¬„ä½
rating_cols = []
for col in df.columns:
    col_lower = col.lower()
    if any(keyword in col_lower for keyword in ['rating', 'score', 'sentiment', 'star']):
        rating_cols.append(col)
        print(f"è©•åˆ†æ¬„ä½: {col}")

# %% åˆ†é¡è®Šæ•¸åˆ†æ
print("\n" + "=" * 80)
print("ğŸ“Š åˆ†é¡è®Šæ•¸åˆ†æ")
print("=" * 80)

categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
# æ’é™¤é•·æ–‡æœ¬æ¬„ä½
categorical_cols = [col for col in categorical_cols if col not in text_cols]

for col in categorical_cols[:5]:  # åªé¡¯ç¤ºå‰5å€‹
    print(f"\n{col}:")
    value_counts = df[col].value_counts().head(10)
    print(value_counts)
    
    # è¦–è¦ºåŒ–
    if len(df[col].unique()) <= 20:
        plt.figure(figsize=(12, 6))
        value_counts.plot(kind='barh', color='steelblue', alpha=0.7)
        plt.title(f'{col} åˆ†ä½ˆ', fontsize=16, fontweight='bold')
        plt.xlabel('æ•¸é‡')
        plt.grid(True, alpha=0.3, axis='x')
        plt.tight_layout()
        plt.savefig(f'visualizations/02_distribution_{col.replace(" ", "_")}.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()

# %% æ–‡æœ¬é•·åº¦åˆ†æ
if text_cols:
    print("\n" + "=" * 80)
    print("ğŸ“ æ–‡æœ¬åˆ†æ")
    print("=" * 80)
    
    for text_col in text_cols[:2]:  # åˆ†æå‰2å€‹æ–‡æœ¬æ¬„ä½
        print(f"\nåˆ†ææ¬„ä½: {text_col}")
        
        # è¨ˆç®—æ–‡æœ¬é•·åº¦
        df[f'{text_col}_length'] = df[text_col].astype(str).str.len()
        df[f'{text_col}_word_count'] = df[text_col].astype(str).str.split().str.len()
        
        print(f"å­—å…ƒæ•¸çµ±è¨ˆ:")
        print(df[f'{text_col}_length'].describe())
        print(f"\nè©æ•¸çµ±è¨ˆ:")
        print(df[f'{text_col}_word_count'].describe())
        
        # è¦–è¦ºåŒ–æ–‡æœ¬é•·åº¦åˆ†ä½ˆ
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        
        # å­—å…ƒæ•¸åˆ†ä½ˆ
        axes[0].hist(df[f'{text_col}_length'].dropna(), bins=50, 
                    color='skyblue', alpha=0.7, edgecolor='black')
        axes[0].set_title(f'{text_col} - å­—å…ƒæ•¸åˆ†ä½ˆ', fontsize=14, fontweight='bold')
        axes[0].set_xlabel('å­—å…ƒæ•¸')
        axes[0].set_ylabel('é »ç‡')
        axes[0].grid(True, alpha=0.3)
        
        # è©æ•¸åˆ†ä½ˆ
        axes[1].hist(df[f'{text_col}_word_count'].dropna(), bins=50, 
                    color='lightcoral', alpha=0.7, edgecolor='black')
        axes[1].set_title(f'{text_col} - è©æ•¸åˆ†ä½ˆ', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('è©æ•¸')
        axes[1].set_ylabel('é »ç‡')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'visualizations/03_text_length_{text_col.replace(" ", "_")}.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()

# %% è©•åˆ†/æƒ…æ„Ÿåˆ†æ
if rating_cols:
    print("\n" + "=" * 80)
    print("â­ è©•åˆ†/æƒ…æ„Ÿåˆ†æ")
    print("=" * 80)
    
    for rating_col in rating_cols[:2]:
        print(f"\nåˆ†ææ¬„ä½: {rating_col}")
        print(df[rating_col].value_counts().sort_index())
        
        # è¦–è¦ºåŒ–
        plt.figure(figsize=(12, 6))
        
        if df[rating_col].dtype in ['int64', 'float64']:
            # æ•¸å€¼è©•åˆ†
            df[rating_col].hist(bins=30, color='gold', alpha=0.7, edgecolor='black')
            plt.title(f'{rating_col} åˆ†ä½ˆ', fontsize=16, fontweight='bold')
            plt.xlabel(rating_col)
            plt.ylabel('é »ç‡')
        else:
            # åˆ†é¡è©•åˆ†
            df[rating_col].value_counts().plot(kind='bar', color='gold', alpha=0.7)
            plt.title(f'{rating_col} åˆ†ä½ˆ', fontsize=16, fontweight='bold')
            plt.xlabel(rating_col)
            plt.ylabel('æ•¸é‡')
            plt.xticks(rotation=45, ha='right')
        
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'visualizations/04_rating_{rating_col.replace(" ", "_")}.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()

# %% ç›¸é—œæ€§åˆ†æ
if len(numeric_cols) > 1:
    print("\n" + "=" * 80)
    print("ğŸ”— ç›¸é—œæ€§åˆ†æ")
    print("=" * 80)
    
    correlation = df[numeric_cols].corr()
    print(correlation)
    
    # ç†±åœ–
    plt.figure(figsize=(12, 10))
    sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', 
                center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8})
    plt.title('ç‰¹å¾µç›¸é—œæ€§ç†±åœ–', fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.savefig('visualizations/05_correlation_heatmap.png', dpi=300, bbox_inches='tight')
    print("âœ… ç›¸é—œæ€§ç†±åœ–å·²ä¿å­˜")
    plt.show()

# %% ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š
print("\n" + "=" * 80)
print("ğŸ’¾ ä¿å­˜æ•¸æ“š")
print("=" * 80)

# ä¿å­˜åŸºæœ¬çµ±è¨ˆ
summary_path = Path('data/processed/eda_summary.txt')
with open(summary_path, 'w', encoding='utf-8') as f:
    f.write("=" * 80 + "\n")
    f.write("EDA æ‘˜è¦å ±å‘Š\n")
    f.write("=" * 80 + "\n\n")
    
    f.write(f"æ•¸æ“šé›†å½¢ç‹€: {df.shape[0]:,} è¡Œ Ã— {df.shape[1]} åˆ—\n\n")
    
    f.write("æ¬„ä½è³‡è¨Š:\n")
    f.write("-" * 80 + "\n")
    for col in df.columns:
        f.write(f"{col}: {df[col].dtype}\n")
    
    f.write("\nç¼ºå¤±å€¼:\n")
    f.write("-" * 80 + "\n")
    f.write(str(missing_df[missing_df['ç¼ºå¤±æ•¸é‡'] > 0]))
    
    if numeric_cols:
        f.write("\n\næ•¸å€¼æ¬„ä½çµ±è¨ˆ:\n")
        f.write("-" * 80 + "\n")
        f.write(str(df[numeric_cols].describe()))

print(f"âœ… EDA æ‘˜è¦å·²ä¿å­˜è‡³: {summary_path}")

# ä¿å­˜å¢å¼·å¾Œçš„æ•¸æ“š
enhanced_path = Path('data/processed/enhanced_data.csv')
df.to_csv(enhanced_path, index=False)
print(f"âœ… å¢å¼·æ•¸æ“šå·²ä¿å­˜è‡³: {enhanced_path}")

# %% ç¸½çµ
print("\n" + "=" * 80)
print("ğŸ‰ EDA å®Œæˆ")
print("=" * 80)
print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  ğŸ“Š è¦–è¦ºåŒ–åœ–è¡¨: visualizations/ ç›®éŒ„")
print(f"  ğŸ“„ EDA æ‘˜è¦: {summary_path}")
print(f"  ğŸ’¾ å¢å¼·æ•¸æ“š: {enhanced_path}")
print("\nä¸‹ä¸€æ­¥: æ•¸æ“šé è™•ç†èˆ‡ç‰¹å¾µå·¥ç¨‹")
print("=" * 80)
